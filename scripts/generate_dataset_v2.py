import numpy as np
import networkx as nx
import os
import multiprocessing
import scipy.linalg
from tqdm import tqdm
import sys
import argparse

# ç¡®ä¿èƒ½æ‰¾åˆ° src åŒ…
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from src.algorithms.falqon_core import FALQON

def get_spectral_decomposition(adj):
    """
    è®¡ç®—å½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ã€‚
    L = I - D^{-1/2} A D^{-1/2}
    """
    N = adj.shape[0]
    deg = np.sum(adj, axis=1)
    # å¤„ç†å­¤ç«‹èŠ‚ç‚¹é˜²æ­¢é™¤é›¶
    d_inv_sqrt = np.power(deg, -0.5, where=deg!=0)
    d_inv_sqrt[deg==0] = 0.0
    D_inv_sqrt = np.diag(d_inv_sqrt)
    
    # å½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ
    L = np.eye(N) - D_inv_sqrt @ adj @ D_inv_sqrt
    
    # ç‰¹å¾åˆ†è§£ (eigh ç”¨äºå¯¹ç§°çŸ©é˜µï¼Œæ›´ç¨³å¥)
    evals, evecs = scipy.linalg.eigh(L)
    
    # æ’åºç‰¹å¾å€¼ (ä»å°åˆ°å¤§)
    idx = np.argsort(evals)
    evals = evals[idx]
    evecs = evecs[:, idx]
    
    return evals, evecs

def generate_single_instance(instance_id):
    try:
        # --- ä¿®æ”¹ç‚¹ 1: æ··åˆç”Ÿæˆç­–ç•¥ (æ”¯æŒæ­£åˆ™å›¾ä»¥éªŒè¯ Kesten-McKay) ---
        # 50% æ¦‚ç‡ç”Ÿæˆ ErdÅ‘s-RÃ©nyi, 50% ç”Ÿæˆéšæœºæ­£åˆ™å›¾
        num_nodes = np.random.randint(6, 14) #ç¨å¾®å¢å¤§ä¸€ç‚¹è§„æ¨¡
        
        if np.random.rand() > 0.5:
            # éšæœºæ­£åˆ™å›¾ (d=3)
            # æ³¨æ„: n * d å¿…é¡»æ˜¯å¶æ•°
            if (num_nodes * 3) % 2 != 0: num_nodes += 1
            g = nx.random_regular_graph(3, num_nodes)
        else:
            # ç»å…¸ ER å›¾
            g = nx.erdos_renyi_graph(num_nodes, p=0.6)

        if not nx.is_connected(g):
            return None

        # --- ä¿®æ”¹ç‚¹ 2: è¿è¡Œ FALQON è·å–æ ‡ç­¾ ---
        falqon = FALQON(g, alpha=1.0) # å¢å¤§ä¸€ç‚¹ alpha åŠ å¿«æ”¶æ•›
        betas, energies = falqon.train(max_layers=40) # å¢åŠ åˆ° 40 å±‚ç”¨äºå­¦ä¹ é•¿ç¨‹ä¾èµ–

        # --- ä¿®æ”¹ç‚¹ 3: æå–è°±ä¿¡æ¯ (æ–°æ¶æ„çš„æ ¸å¿ƒè¾“å…¥) ---
        adj = nx.to_numpy_array(g)
        evals, evecs = get_spectral_decomposition(adj)

        return {
            "node_count": num_nodes,
            "adj": adj,
            "evals": evals.astype(np.float32), # ç‰¹å¾å€¼ [N]
            "evecs": evecs.astype(np.float32), # ç‰¹å¾å‘é‡ [N, N]
            "betas": np.array(betas).astype(np.float32),
            "energies": np.array(energies).astype(np.float32)
        }
    except Exception as e:
        # print(f"Error: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description="Generate spectral dataset for FALQON.")
    parser.add_argument("--start", type=int, default=0, help="Start index of samples.")
    parser.add_argument("--end", type=int, default=20000, help="End index of samples.")
    parser.add_argument("--part_id", type=int, default=0, help="Part ID for file naming.")
    parser.add_argument("--output_dir", type=str, default="data/raw/dataset_v2", help="Output directory.")
    parser.add_argument("--cores", type=int, default=32, help="Number of CPU cores to use.")
    args = parser.parse_args()

    num_samples = args.end - args.start
    output_dir = args.output_dir
    os.makedirs(output_dir, exist_ok=True)
    
    num_cores = args.cores
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆè°±-æ—¶åºæ•°æ®é›† (Tasks: {args.start}-{args.end}, Part: {args.part_id})...")
    
    results = []
    with multiprocessing.Pool(processes=num_cores) as pool:
        for res in tqdm(pool.imap_unordered(generate_single_instance, range(num_samples)), total=num_samples):
            if res is not None:
                results.append(res)
                
    save_path = os.path.join(output_dir, f"part_{args.part_id}.npz")
    np.savez_compressed(save_path, data=results)
    print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæ¯•: {save_path}")

if __name__ == "__main__":
    main()
