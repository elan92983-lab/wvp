import numpy as np
import networkx as nx
import os
import multiprocessing
from tqdm import tqdm
from src.algorithms.falqon_core import FALQON

def generate_single_instance(instance_id):
    """
    å•ä¸ªæ ·æœ¬ç”Ÿæˆä»»åŠ¡ï¼šç”Ÿæˆéšæœºå›¾å¹¶è¿è¡Œ FALQON è·å–æ•™å¸ˆç»éªŒæ•°æ®ã€‚
    """
    try:
        # 1. éšæœºç”ŸæˆèŠ‚ç‚¹æ•° (é’ˆå¯¹ 2026 å¹´åˆæœŸ FTQC ç ”ç©¶ï¼Œå»ºè®®å…ˆä» 4-10 ä¸ªæ¯”ç‰¹å¼€å§‹)
        num_nodes = np.random.randint(4, 11)
        
        # 2. ç”Ÿæˆ ErdÅ‘s-RÃ©nyi éšæœºå›¾ï¼Œæ¦‚ç‡ p ä¸º 0.5 ç¡®ä¿å¤æ‚åº¦
        g = nx.erdos_renyi_graph(num_nodes, p=0.5)
        
        # ç¡®ä¿å›¾æ˜¯è¿é€šçš„ï¼Œå¦åˆ™ MaxCut é—®é¢˜ä¼šé€€åŒ–
        if not nx.is_connected(g):
            return None

        # 3. å®ä¾‹åŒ–æ•™å¸ˆæ¨¡å‹ (FALQON)
        # alpha=0.5 æ˜¯æ–‡çŒ® [3] æ¨èçš„æ­¥é•¿ï¼Œæœ‰åŠ©äºæ•æ‰â€œå³°-å°¾â€ç»“æ„
        falqon = FALQON(g, alpha=0.5)
        
        # 4. è¿è¡Œæ¼”åŒ–ï¼Œè·å– 30 å±‚çš„å‚æ•°åºåˆ—
        # å¢åŠ å±‚æ•°æœ‰åŠ©äº Transformer å­¦ä¹ é•¿åºåˆ—è§„å¾‹
        betas, energies = falqon.train(max_layers=30)
        
        # 5. è¿”å›ç»“æœå­—å…¸
        return {
            "node_count": num_nodes,
            "adj": nx.to_numpy_array(g), # å›¾çš„é‚»æ¥çŸ©é˜µï¼ˆTransformer çš„è¾“å…¥ï¼‰
            "betas": np.array(betas),    # æœ€ä¼˜å‚æ•°æ›²çº¿ï¼ˆTransformer çš„æ ‡ç­¾ï¼‰
            "energies": np.array(energies)
        }
    except Exception as e:
        return None

def main():
    # è®¾å®šç”Ÿæˆè§„æ¨¡
    num_samples = 10000  # å¯¹åº” 2026 å¼€å‘åè®®ä¸­çš„æ•°æ®è§„æ¨¡éœ€æ±‚
    output_dir = "data/raw/dataset_v1"
    os.makedirs(output_dir, exist_ok=True)

    print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œæ•°æ®å·¥å‚...")
    print(f"ç›®æ ‡ï¼šç”Ÿæˆ {num_samples} ä¸ª FALQON æ•™å¸ˆæ ·æœ¬")
    
    # è·å– CPU æ ¸å¿ƒæ•°ï¼Œä¿ç•™ 1-2 ä¸ªæ ¸å¿ƒä»¥é˜²æœåŠ¡å™¨æ­»æœº
    num_cores = 32
    print(f"ä½¿ç”¨æ ¸å¿ƒæ•°: {num_cores}")

    results = []
    # ä½¿ç”¨è¿›ç¨‹æ± è¿›è¡Œå¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—
    with multiprocessing.Pool(processes=num_cores) as pool:
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
        for res in tqdm(pool.imap_unordered(generate_single_instance, range(num_samples)), total=num_samples):
            if res is not None:
                results.append(res)
    
    # 6. ä¿å­˜ä¸ºå‹ç¼©æ ¼å¼ï¼ŒèŠ‚çœæœåŠ¡å™¨ç£ç›˜ç©ºé—´
    save_path = f"{output_dir}/train_data.npz"
    np.savez_compressed(save_path, data=results)
    
    print(f"\nâœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
    print(f"æœ‰æ•ˆæ ·æœ¬æ•°: {len(results)}")
    print(f"ä¿å­˜è·¯å¾„: {save_path}")

if __name__ == "__main__":
    main()
