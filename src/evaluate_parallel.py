import torch
import numpy as np
import networkx as nx
import multiprocessing
from functools import partial
import tqdm
import sys
import os
from scipy.linalg import expm
from qiskit.quantum_info import Statevector

from src.models.transformer import FALQONTransformer
from src.algorithms.falqon_core import FALQON

# ---------------------------------------------------------
# æ ¸å¿ƒè®¡ç®—å‡½æ•°ï¼šä¼šè¢«å¤šä¸ª CPU æ ¸å¿ƒå¹¶è¡Œè°ƒç”¨
# ---------------------------------------------------------
def evaluate_single_instance(instance_id, model_state_dict, device_str, n_nodes=12):
    # æ¯ä¸ªè¿›ç¨‹å†…éƒ¨é‡æ–°åˆå§‹åŒ–ç¯å¢ƒï¼Œé¿å…èµ„æºç«äº‰
    device = torch.device(device_str)
    # ç¡®ä¿ d_model ä¸ä½ æ–¹æ¡ˆäºŒè®­ç»ƒæ—¶ä¸€è‡´ (64)
    model = FALQONTransformer(max_nodes=12, output_len=30, d_model=64).to(device)
    model.load_state_dict(model_state_dict)
    model.eval()

    # 1. ç”Ÿæˆéšæœºå›¾ (12 èŠ‚ç‚¹)
    g = nx.erdos_renyi_graph(n_nodes, p=0.5)
    while not nx.is_connected(g):
        g = nx.erdos_renyi_graph(n_nodes, p=0.5)

    # 2. Teacher (ç»å…¸ FALQON)
    teacher = FALQON(g, alpha=0.5)
    _, teacher_energies = teacher.train(max_layers=30)
    e_true = teacher_energies[-1]

    # 3. Student (AI é¢„æµ‹)
    adj = nx.to_numpy_array(g)
    padded_adj = np.zeros((12, 12), dtype=np.float32)
    padded_adj[:n_nodes, :n_nodes] = adj
    mask = np.zeros(12, dtype=np.float32)
    mask[:n_nodes] = 1.0

    adj_t = torch.tensor(padded_adj).unsqueeze(0).to(device).float()
    mask_t = torch.tensor(mask).unsqueeze(0).to(device).float()

    with torch.no_grad():
        pred_betas = model(adj_t, mask_t).cpu().numpy().flatten()

    # 4. æ‰§è¡Œé¢„æµ‹å‚æ•°çš„æ¼”åŒ–
    hp_mat = teacher.Hp.to_matrix()
    hd_mat = teacher.Hd.to_matrix()
    current_state = Statevector.from_label('+' * n_nodes)
    u_p = expm(-1j * hp_mat * 1.0)
    
    for b in pred_betas:
        current_state = current_state.evolve(u_p)
        # æ¼”åŒ–çŸ©é˜µåº”ç”¨
        u_d = expm(-1j * hd_mat * b)
        current_state = current_state.evolve(u_d)
        
    e_ai = current_state.expectation_value(hp_mat).real

    # 5. è®¡ç®— Cut Value æ¯”å€¼ (AR)
    num_edges = len(g.edges)
    cut_true = 0.5 * (num_edges - 2 * e_true)
    cut_ai = 0.5 * (num_edges - 2 * e_ai)
    
    return cut_ai / cut_true if cut_true > 1e-6 else None

def main():
    # æ¥æ”¶å‘½ä»¤è¡Œå‚æ•°ï¼špython src/evaluate_parallel.py [start_idx] [num_per_job]
    start_idx = int(sys.argv[1]) if len(sys.argv) > 1 else 0
    num_per_job = int(sys.argv[2]) if len(sys.argv) > 2 else 10
    
    model_path = "models/checkpoints/best_model.pth"
    n_nodes = 12  
    device_str = "cpu"
    
    if not os.path.exists(model_path):
        print(f"Error: {model_path} not found")
        return

    state_dict = torch.load(model_path, map_location=device_str)
    num_cores = int(multiprocessing.cpu_count())
    
    print(f"ğŸš€ å­ä»»åŠ¡å¯åŠ¨ | èŒƒå›´: {start_idx} åˆ° {start_idx + num_per_job} | æ ¸å¿ƒæ•°: {num_cores}")

    # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œè®¡ç®—å½“å‰èŒƒå›´å†…çš„æ ·æœ¬
    with multiprocessing.Pool(processes=num_cores) as pool:
        func = partial(evaluate_single_instance, model_state_dict=state_dict, device_str=device_str, n_nodes=n_nodes)
        results = list(tqdm.tqdm(pool.imap(func, range(num_per_job)), total=num_per_job))

    # è¿‡æ»¤ None å¹¶ä¿å­˜æœ¬ç‰‡æ®µç»“æœ
    ar_list = [r for r in results if r is not None]
    
    os.makedirs("output/ar_parts", exist_ok=True)
    save_path = f"output/ar_parts/part_{start_idx}.npy"
    np.save(save_path, np.array(ar_list))
    
    print(f"ğŸ’¾ ç‰‡æ®µè®¡ç®—å®Œæˆï¼Œç»“æœä¿å­˜è‡³: {save_path}")

if __name__ == "__main__":
    main()